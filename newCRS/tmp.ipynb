{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "# Assuming 'args.device' is set to 'cuda' if a GPU is available, else 'cpu'\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load the pre-trained RoBERTa model for sequence classification\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model = model.to(device)\n",
    "\n",
    "# Load the tokenizer\n",
    "senti_tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# Sample text\n",
    "text = \"User: I like to watch scary movies\"\n",
    "\n",
    "# Tokenize the text\n",
    "inputs = senti_tokenizer(text, return_tensors=\"pt\")#, padding=True, truncation=True)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# Get the logits from the model\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits\n",
    "\n",
    "# Apply softmax to get probabilities\n",
    "probabilities = torch.nn.functional.softmax(logits, dim=1).cpu().numpy()\n",
    "\n",
    "# Note: twitter-roberta-senti model => [negative, neutral, positive]\n",
    "negative, neutral, positive = probabilities[0]\n",
    "sentiment_score = positive / (positive + negative)\n",
    "\n",
    "print(sentiment_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestLoop():\n",
    "    def __init__(self, args, test_dataloader, save_name, epoch_num):\n",
    "      self.device = args.device\n",
    "      self.save_name = save_name\n",
    "      self.epoch_num = epoch_num \n",
    "    \n",
    "      self.test_dataloader = test_dataloader\n",
    "      \n",
    "      self.rec_model = RecModel(args.kg_emb_dim, n_entity=kg['num_entities'], num_relations=kg['num_relations'], \n",
    "                    num_bases=args.num_bases, edge_index=kg['edge_index'], edge_type=kg['edge_type'],\n",
    "                    device=self.device)\n",
    "\n",
    "      self.rec_model.to(self.device)\n",
    "      \n",
    "      self.rec_evaluator = RecEvaluator()\n",
    "      \n",
    "      self.best_metric_dir = os.path.join(args.output_dir, 'best')\n",
    "    \n",
    "    def load_model(self):\n",
    "        self.rec_model.load_state_dict(torch.load(self.best_metric_dir + f'epoch_{self.epoch_num}_{self.save_name}.pth'))\n",
    "        \n",
    "    def test(self):\n",
    "        logger.info('>>>>>>>>>>>>>>>>> Test Evaluation')\n",
    "        self.load_model()\n",
    "        self.rec_model.eval()\n",
    "        \n",
    "        test_loss = []\n",
    "        for step, batch in enumerate(tqdm(self.test_dataloader)):\n",
    "            with torch.no_grad():\n",
    "                rec_score, rec_loss = self.rec_model(batch)\n",
    "                test_loss.append(rec_loss)\n",
    "                \n",
    "                score = rec_score[:, kg['item_ids']]\n",
    "                ranks = torch.topk(score, k=50, dim=-1).indices.tolist()\n",
    "                ranks = [[kg['item_ids'][rank] for rank in batch_rank] for batch_rank in ranks] # 각 배치에 대한 상위 50개 엔티티의 인덱스 리스트\n",
    "                labels = batch['context']['rec_labels']\n",
    "                self.rec_evaluator.evaluate(ranks, labels)\n",
    "                \n",
    "        # metric\n",
    "        metric_report = self.rec_evaluator.report()\n",
    "        for k, v in metric_report.items():\n",
    "            metric_report[k] = v.sum().item()\n",
    "            \n",
    "        test_report = {}\n",
    "        for k, v in metric_report.items():\n",
    "            if k != 'count':\n",
    "                test_report[f'test/{k}'] = v / metric_report['count']\n",
    "        \n",
    "        test_report['valid/loss'] = np.mean(test_loss)\n",
    "        # test_report['epoch'] = epoch\n",
    "        \n",
    "        logger.info(f'{test_report}')\n",
    "        logger.info('end of test')\n",
    "        \n",
    "        self.rec_evaluator.reset_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieMentions= {\"173191\": \"House at the End of the Street (2012)\", \"205430\": \"A Quiet Place (2018)\", \"118338\": \"The Forest  (2016)\", \"177915\": \"Uncle Buck\", \"132562\": \"The Last House on the Left  (1972)\", \"76279\": \"Death at a Funeral  (2007)\", \"158950\": \"The Last House on the Left  (2009)\", \"144779\": \"Annabelle 2 (2017)\"}\n",
    "\n",
    "seekerPolarity= {\"173191\": {\"suggested\": 1, \"seen\": 2, \"liked\": 2}, \"205430\": {\"suggested\": 0, \"seen\": 0, \"liked\": 2}, \"118338\": {\"suggested\": 0, \"seen\": 1, \"liked\": 1}, \"177915\": {\"suggested\": 0, \"seen\": 1, \"liked\": 1}, \"132562\": {\"suggested\": 0, \"seen\": 1, \"liked\": 1}, \"76279\": {\"suggested\": 1, \"seen\": 0, \"liked\": 2}, \"158950\": {\"suggested\": 0, \"seen\": 1, \"liked\": 1}, \"144779\": {\"suggested\": 1, \"seen\": 1, \"liked\": 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'173191': 'House at the End of the Street (2012)',\n",
       " '205430': 'A Quiet Place (2018)',\n",
       " '118338': 'The Forest  (2016)',\n",
       " '177915': 'Uncle Buck',\n",
       " '132562': 'The Last House on the Left  (1972)',\n",
       " '76279': 'Death at a Funeral  (2007)',\n",
       " '158950': 'The Last House on the Left  (2009)',\n",
       " '144779': 'Annabelle 2 (2017)'}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieMentions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'173191': {'suggested': 1, 'seen': 2, 'liked': 2},\n",
       " '205430': {'suggested': 0, 'seen': 0, 'liked': 2},\n",
       " '118338': {'suggested': 0, 'seen': 1, 'liked': 1},\n",
       " '177915': {'suggested': 0, 'seen': 1, 'liked': 1},\n",
       " '132562': {'suggested': 0, 'seen': 1, 'liked': 1},\n",
       " '76279': {'suggested': 1, 'seen': 0, 'liked': 2},\n",
       " '158950': {'suggested': 0, 'seen': 1, 'liked': 1},\n",
       " '144779': {'suggested': 1, 'seen': 1, 'liked': 1}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seekerPolarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssas = [173191]\n",
    "ori_movie_id = \"173191\"\n",
    "int(ori_movie_id) in ssas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultdict({'20001': \n",
    "                    {'111776': 'Super Troopers (2001)',\n",
    "                    '91481': 'Beverly Hills Cop (1984)',\n",
    "                    '151656': 'Police Academy  (1984)',\n",
    "                    '134643': 'American Pie  (1999)',\n",
    "                    '192131': 'American Pie ',\n",
    "                    '124771': '48 Hrs. (1982)',\n",
    "                    '94688': 'Police Academy 2: Their First Assignment (1985)',\n",
    "                    '101794': 'Lethal Weapon (1987)'})\n",
    "            \n",
    "            \n",
    "\"aspects\": [18292] # movieid = 111776"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redial_mv_id = re.findall(r'@(\\d+)', message[\"text\"])\n",
    "\n",
    "여러개면,, \n",
    "for mv_id in redial_mv_id:\n",
    "    mv_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"76012\": 29959 (entity_mv_id)\n",
    "\n",
    "\n",
    "except:\n",
    "    for k, v in new_redial_movie_id2_entityid.items():\n",
    "        if v == entity_mv_id:\n",
    "            try: # 동일 entity id가 여러 key (original redial movie id)에 매핑되었을 수도 있음\n",
    "                movie_title = movieid2name[v]\n",
    "            except:\n",
    "                continue"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
