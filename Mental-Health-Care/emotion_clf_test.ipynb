{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.metrics import matthews_corrcoef, f1_score\n",
    "\n",
    "import datetime\n",
    "from termcolor import colored\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. class BASE\n",
    "- metric 관련 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BASE(nn.Module):\n",
    "    '''\n",
    "        BASE model\n",
    "    '''\n",
    "    def __init__(self, args):\n",
    "        super(BASE, self).__init__()\n",
    "        self.args = args\n",
    "\n",
    "        # cached tensor for speed\n",
    "        # self.I_way = nn.Parameter(torch.eye(self.args.way, dtype=torch.float),\n",
    "        #                           requires_grad=False)\n",
    "    \n",
    "    @staticmethod\n",
    "    def compute_acc(pred, true, dim=1, nomax=False):\n",
    "        '''\n",
    "            Compute the accuracy.\n",
    "            @param pred: batch_size * num_classes\n",
    "            @param true: batch_size\n",
    "        '''\n",
    "        if nomax: return torch.mean((pred == true).float()).item()\n",
    "        else: return torch.mean((torch.argmax(pred, dim=dim) == true).float()).item()\n",
    "        \n",
    "    @staticmethod\n",
    "    def compute_f1(y_pred, true, dim=1, nomax=False,  labels=None, average='weighted'):\n",
    "        '''\n",
    "            Compute the weighted f1 score.\n",
    "            @param pred: batch_size * num_classes\n",
    "            @param true: batch_size\n",
    "        '''\n",
    "        if not nomax: _, y_pred = torch.max(y_pred, dim)\n",
    "\n",
    "        f1 = f1_score(true.cpu().detach().numpy(), y_pred.cpu().detach().numpy(), average=average, labels=labels )\n",
    "\n",
    "        return f1\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_mcc(y_pred, true, dim=1, nomax=False):\n",
    "        '''\n",
    "            Compute the matthews correlation coeficient.\n",
    "            @param pred: batch_size * num_classes\n",
    "            @param true: batch_size\n",
    "        '''\n",
    "        if not nomax: _, y_pred = torch.max(y_pred, dim)\n",
    "\n",
    "        mcc = matthews_corrcoef(true.cpu().detach().numpy(), y_pred.cpu().detach().numpy())\n",
    "\n",
    "        return mcc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test 함수\n",
    "- model output(=logits)과 label과의 cross-entropy 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_data, model, args, verbose=True, target='val', loader=None):\n",
    "    '''\n",
    "        Evaluate the model on a bag of sampled tasks. Return the mean accuracy, \n",
    "        the weighted f1 score and the matthew correlation coeficient and their\n",
    "        associated std. (ensure the model used is modified to return the values)\n",
    "    '''\n",
    "    model['ebd'].eval()\n",
    "    model['clf'].eval()\n",
    "\n",
    "    acc, f1, mcc, f1_micro, trues, preds = [], [], [], [], [], []\n",
    "    # if loader is None:\n",
    "    #     loader = DataLoader(SupervisedDataset(test_data, args), batch_size=args.batch_size, num_workers=2, shuffle=False)\n",
    "\n",
    "    for batch in tqdm(loader, desc=colored('Testing regular on %s' % (target), 'yellow'), total=loader.__len__()):\n",
    "        #res_acc, res_f1, res_mcc, res_f1_micro, res_pred, res_true = test_one(batch, model, args, out=(target=='test'))\n",
    "        res_acc, res_f1, res_mcc = test_one(batch, model, args, out=(target=='test'))\n",
    "        acc.append(res_acc)\n",
    "        f1.append(res_f1)\n",
    "        mcc.append(res_mcc)\n",
    "\n",
    "    acc, f1, mcc = np.array(acc), np.array(f1), np.array(mcc)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"{}, {:s} {:>7.4f} ({:s} {:>7.4f}), {:s} {:>7.4f} ({:s} {:>7.4f}), {:s} {:>7.4f} ({:s} {:>7.4f})\".format(\n",
    "                datetime.datetime.now().strftime('%02y/%02m/%02d %H:%M:%S'),\n",
    "                colored(\"acc mean\", \"blue\"),\n",
    "                np.mean(acc),\n",
    "                colored(\"std\", \"blue\"),\n",
    "                np.std(acc),\n",
    "                colored(\"f1 mean\", \"blue\"),\n",
    "                np.mean(f1),\n",
    "                colored(\"std\", \"blue\"),\n",
    "                np.std(f1),\n",
    "                colored(\"mcc mean\", \"blue\"),\n",
    "                np.mean(mcc),\n",
    "                colored(\"std\", \"blue\"),\n",
    "                np.std(mcc),\n",
    "                colored(\"f1 micro mean\", \"blue\"),\n",
    "                ), flush=True)\n",
    "\n",
    "        # latex table\n",
    "        print(\"{:s} & {:s} & {:>7.4f} \\\\tiny $\\\\pm {:>7.4f}$ & {:>7.4f} \\\\tiny $\\\\pm {:>7.4f}$ & {:>7.4f} \\\\tiny $\\\\pm {:>7.4f}$\".format(\n",
    "                args.embedding.replace('_', '\\\\_'),\n",
    "                args.classifier.replace('_', '\\\\_'),\n",
    "                np.mean(acc),\n",
    "                np.std(acc),\n",
    "                np.mean(f1),\n",
    "                np.std(f1),\n",
    "                np.mean(mcc),\n",
    "                np.std(mcc),\n",
    "                ), flush=True)\n",
    "   \n",
    "    return np.mean(acc), np.std(acc), np.mean(f1), np.std(f1), np.mean(mcc), np.std(mcc)\n",
    "\n",
    "\n",
    "def test_one(batch, model, args, out=False):\n",
    "    '''\n",
    "        Evaluate the model on one sampled task. Return the accuracy.\n",
    "    '''\n",
    "\n",
    "    batch['text'] = batch['text'].to(device)\n",
    "    batch['label'] = batch['label'].to(device)\n",
    "\n",
    "    # Embedding the document\n",
    "    XS = model['ebd'](batch) # embedding된 input data (=calibration data)\n",
    "    YS = batch['label']\n",
    "\n",
    "    out_XS = model['clf'](XS, YS=None)\n",
    "\n",
    "    output = out_XS.view(-1, args.n_classes)  # new shape: [32*35, 7]\n",
    "    target = YS.view(-1)  # new shape: [32*35]\n",
    "\n",
    "    #loss = F.cross_entropy(output, YS)\n",
    "    acc = BASE.compute_acc(output, target)\n",
    "    f1 = BASE.compute_f1(output, target)\n",
    "    mcc = BASE.compute_mcc(output, target)\n",
    "    return acc, f1, mcc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc, test_std, _, _, _, _ = test(test_data, model, args, target='test', loader=test_loader)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
