{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2l31XISj3Kj",
        "outputId": "27050b58-5452-4f3d-d4e9-fd7e2c7b2a5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ik388LUojqdr",
        "outputId": "8773dfee-ac4f-4cf2-f045-7755b806544d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/EMRES\n"
          ]
        }
      ],
      "source": [
        "cd '/content/drive/MyDrive/EMRES'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tdZieZIeTa9",
        "outputId": "c4ab557f-cbc1-4ee0-edee-65730973f38b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting onnx\n",
            "  Downloading onnx-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n",
            "Installing collected packages: onnx\n",
            "Successfully installed onnx-1.15.0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "!pip install onnx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7gB3CcRtjYRb"
      },
      "outputs": [],
      "source": [
        "music_feature_norm = torch.load('music_feature_norm.pt')\n",
        "music_emotion_norm = torch.load('music_emotion_norm.pt')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZRPsp76kgZT"
      },
      "source": [
        "input 선택\n",
        "\n",
        "원래는 사용자의 현재 감정유사도를 기반으로 해야하지만 argMax가 없으니 했다고 가정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SiZFbLmhkhgZ"
      },
      "outputs": [],
      "source": [
        "first_vector_feature = music_feature_norm[0] #shape이 (124,) 입력으로 들어갈 것\n",
        "first_vector_emotion = music_emotion_norm[0] #shape이 (2,) 입력으로 들어갈 것"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4qYnsIOhm28F"
      },
      "outputs": [],
      "source": [
        "first_vector_feature = first_vector_feature.unsqueeze(0).unsqueeze(1)\n",
        "first_vector_emotion = first_vector_emotion.unsqueeze(0).unsqueeze(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nY4__tF8m-eE"
      },
      "outputs": [],
      "source": [
        "music_feature_norm_add = music_feature_norm.unsqueeze(2)\n",
        "music_emotion_norm_add = music_emotion_norm.unsqueeze(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JT7MRvJ4nLbq",
        "outputId": "3ec10bcf-748a-42be-8071-b6a6c6107714"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 124])\n",
            "torch.Size([1, 1, 2])\n",
            "torch.Size([34, 124, 1])\n",
            "torch.Size([34, 2, 1])\n"
          ]
        }
      ],
      "source": [
        "print(first_vector_feature.shape)\n",
        "print(first_vector_emotion.shape)\n",
        "print(music_feature_norm_add.shape)\n",
        "print(music_emotion_norm_add.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_20E2wsfmf-"
      },
      "source": [
        "argmax가 안되니까\n",
        "모델 입력으로 이미 사용자가 고른 노래의 feauture(normalized)와 emotion(normalized)가 들어옴\n",
        "\n",
        "normalize는 cos유사도를 해야하는데, 크기구하는 메서드가 없기 때문에 크기를 1로 만들어주려는 것\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "노래 번호도 원래 인덱싱으로 뽑아야하는데 일단은 34곡에 대해서만 0부터 시작하는 걸로 수정"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmw6nRpxkoxs"
      },
      "outputs": [],
      "source": [
        "class EMRES(nn.Module):\n",
        "    def __init__(self, music_emotion, music_feature):\n",
        "        super().__init__()\n",
        "        self.n = 16\n",
        "\n",
        "        self.alpha = nn.Parameter(torch.ones(1,)*0.2, requires_grad=False)\n",
        "        self.beta = nn.Parameter(torch.ones(1,)*0.8, requires_grad=False)\n",
        "\n",
        "\n",
        "        self.music_emotion = music_emotion.squeeze(2)\n",
        "        self.music_feature = music_feature.squeeze(2)\n",
        "\n",
        "        self.similarity_emotion = nn.Linear(2, 34, bias=False)\n",
        "        self.similarity_emotion.weight.data = self.music_emotion\n",
        "        self.similarity_emotion.weight.requires_grad = False\n",
        "\n",
        "\n",
        "        self.similarity_feature = nn.Linear(124, 34, bias=False)\n",
        "        self.similarity_feature.weight.data = self.music_feature\n",
        "        self.similarity_feature.weight.requires_grad = False\n",
        "\n",
        "    def forward(self, user_com):\n",
        "        usermusic_emotion = user_com[:,:,:2]\n",
        "        usermusic_feature = user_com[:,:,2:]\n",
        "        #  아래 2줄로 인해 multi input error 발생\n",
        "        cos_emotion = self.similarity_emotion(usermusic_emotion)\n",
        "        cos_feature = self.similarity_feature(usermusic_feature)\n",
        "\n",
        "        out = self.alpha * cos_emotion + self.beta * cos_feature\n",
        "        print(out.shape)\n",
        "        return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EGwqOabo2TZ",
        "outputId": "8f7bb346-2a0f-4724-b154-22814493b334"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1, 1, 34])\n"
          ]
        }
      ],
      "source": [
        "usermusic_emotion = torch.rand(1,1,2)\n",
        "usermusic_feature = torch.rand(1,1,124)\n",
        "user_com = torch.cat([usermusic_emotion,usermusic_feature],2)\n",
        "emres = EMRES(music_emotion_norm_add, music_feature_norm_add)\n",
        "emres.eval()\n",
        "torch.onnx.export(emres,user_com, \"EMRES_ONNX.onnx\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ATLzJ7vFoT5f"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vEfv5XB1kpiT"
      },
      "source": [
        "사용자 input - 예시 : [(143, 1, 3), (381, 1, 2), (388, 1, 4), (389, 1, 4)] -\n",
        "\n",
        "텐서로 만들자면 (1,데이터 개수, 곡의 제목)으로 하고 요소값을 감정으로 하면 될듯(1은 배치용)\n",
        "\n",
        "리스트안에 여러 요소가 있고 각 요소는 곡 제목, 좋아요, 노래들을 때의 감정\n",
        "\n",
        "노래 input\n",
        "\n",
        "music_vectors (1,곡의 제목, 벡터)\n",
        "\n",
        "music_emotion(1, 곡의 제목, 벡터)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
