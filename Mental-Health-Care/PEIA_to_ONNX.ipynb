{"cells":[{"cell_type":"markdown","metadata":{"id":"YkdzWU2bRBpr"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3069,"status":"ok","timestamp":1698309243635,"user":{"displayName":"박요한","userId":"18078957727534871434"},"user_tz":-540},"id":"BWY0RxUSWn6N","outputId":"1f14fb7b-92be-43ee-bc44-b0813f16abbc"},"outputs":[{"name":"stdout","output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1698309243635,"user":{"displayName":"박요한","userId":"18078957727534871434"},"user_tz":-540},"id":"7QW831c8WRZ3","outputId":"67ae5808-45f5-478f-96e5-e06259b6dc52"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/MyDrive/peia\n"]}],"source":["cd \"/content/drive/MyDrive/peia\""]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4166,"status":"ok","timestamp":1698309247797,"user":{"displayName":"박요한","userId":"18078957727534871434"},"user_tz":-540},"id":"3I3mUai1WKxj","outputId":"1f7cd711-f339-4dca-bc4d-4283d46a6476"},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: onnx in /usr/local/lib/python3.10/dist-packages (1.14.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from onnx) (1.23.5)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n","Requirement already satisfied: typing-extensions>=3.6.2.1 in /usr/local/lib/python3.10/dist-packages (from onnx) (4.5.0)\n"]}],"source":["pip install onnx"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zaA3xLeQVY85"},"outputs":[],"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as f\n","import numpy as np\n","\n","class DNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, num_hidden_layers, dropout=0.1):\n","        super().__init__()\n","        self.layers = nn.Sequential(\n","            nn.Linear(input_size, 4*hidden_size),\n","            nn.ReLU(),\n","            *[nn.Sequential(nn.Linear(4*hidden_size, 4*hidden_size), nn.ReLU(), nn.Dropout(dropout)) for _ in range(num_hidden_layers)],\n","            nn.Linear(4*hidden_size, hidden_size),\n","        )\n","    def forward(self, x):\n","        return self.layers(x)\n","\n","class Score(nn.Module):\n","    def __init__(self, d_model):\n","        super().__init__()\n","\n","        self.layers = nn.Sequential(\n","            nn.Linear(d_model, d_model),\n","            nn.Sigmoid(),\n","            nn.Linear(d_model, 1),\n","        )\n","\n","    def forward(self, x):\n","        return self.layers(x)\n","\n","class MultiHeadAttention(nn.Module):\n","    def __init__(self, d_model,dropout=0.1):\n","        super().__init__()\n","\n","        self.linear = nn.Linear(d_model*d_model, d_model)\n","        self.l_to_score, self.s_to_score, self.d_to_score = [Score(d_model) for _ in range(3)]\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, user_embedded, mood_embedded, genre_embedded):\n","        l = (user_embedded.unsqueeze(2)*genre_embedded.unsqueeze(1)).reshape(genre_embedded.shape[0], 6, -1)\n","\n","        l_score = self.l_to_score(l)\n","\n","        alpha = f.softmax(l_score, dim=1)\n","        l_att = (alpha * l).sum(dim=1)\n","\n","        s = (mood_embedded.unsqueeze(2)*genre_embedded.unsqueeze(1)).reshape(genre_embedded.shape[0], 2, -1)\n","\n","        s_score = self.s_to_score(s)\n","\n","        beta = f.softmax(s_score,dim=1)\n","        s_att = (beta*s).sum(dim=1)\n","\n","        ddl = self.d_to_score(l_att)\n","\n","        dds = self.d_to_score(s_att)\n","\n","        dl = torch.exp(ddl)/(torch.exp(ddl)+torch.exp(dds))\n","        ds = torch.exp(dds)/(torch.exp(ddl)+torch.exp(dds))\n","\n","        out = dl * l_att + ds * s_att\n","\n","        return out, dl, ds\n","\n","class Embeddings(nn.Module):\n","    def __init__(self, d_model,dropout=0.1):\n","        super().__init__()\n","        self.linear = nn.Linear(1,d_model)\n","        self.dropout = nn.Dropout(dropout)\n","\n","    def forward(self, input):\n","        linear_output = self.linear(input)\n","        embeddings = self.dropout(linear_output)\n","        return embeddings\n","\n","class Embedder(nn.Module):\n","    def __init__(self,d_model):\n","        super().__init__()\n","\n","        self.user_embedding = Embeddings(d_model)\n","        self.mood_embedding = Embeddings(d_model)\n","        self.genre_embedding = Embeddings(d_model)\n","\n","    def forward(self, user_v, mood_v, genre_v):\n","        user_embedded = self.user_embedding(user_v)\n","        mood_embedded = self.mood_embedding(mood_v)\n","        genre_embedded = self.genre_embedding(genre_v)\n","\n","        return user_embedded, mood_embedded, genre_embedded\n","\n","class TransformerClassifier(nn.Module):\n","    def __init__(self, d_model, user_num, mood_num, genre_num, num_hidden_layers, dropout=0.1):\n","        super().__init__()\n","\n","        self.all_num = user_num + mood_num + genre_num\n","\n","        self.embedder = Embedder(d_model)\n","        self.mha = MultiHeadAttention(d_model)\n","        self.dnn = DNN(d_model*self.all_num, d_model, num_hidden_layers)\n","\n","        self.W_zd = nn.Linear(d_model, 10, bias=False)\n","        self.W_z0 = nn.Linear(self.all_num, 10, bias=False)\n","        self.W_zatt = nn.Linear(d_model, 10, bias=False)\n","        self.bias = nn.Parameter(torch.zeros(10))\n","\n","    def forward(self, user_v, mood_v, genre_v):\n","\n","        user_embedded, mood_embedded, genre_embedded = self.embedder(user_v, mood_v, genre_v)\n","\n","        all_embedded_values = torch.cat([user_embedded, mood_embedded, genre_embedded], dim=1)\n","\n","        all_embedded_values_r = all_embedded_values.reshape(all_embedded_values.shape[0], -1)\n","\n","        zd = self.dnn(all_embedded_values_r)\n","\n","        z0 = torch.cat((user_v, mood_v, genre_v), dim=1)\n","\n","        z0_r = z0.reshape(z0.shape[0],-1)\n","\n","        zatt, rl, rs = self.mha(user_embedded,mood_embedded, genre_embedded)\n","\n","        out = torch.sigmoid(self.W_zd(zd) + self.W_z0(z0_r) + self.W_zatt(zatt) + self.bias)\n","\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XNHSUFGyYox-"},"outputs":[],"source":["device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","user_v = torch.rand(1,3,1).to(device)\n","mood_v = torch.rand(1,1,1).to(device)\n","genre_v = torch.rand(1,2,1).to(device)\n","\n","x = (user_v, mood_v, genre_v)\n","model_params = torch.load('model_parameters_label.pt', map_location=device)\n","model = TransformerClassifier(d_model=8, user_num=user_v.shape[1], mood_num=mood_v.shape[1], genre_num = genre_v.shape[1], num_hidden_layers=2).to(device)\n","model.load_state_dict(model_params)\n","model.eval()\n","torch.onnx.export(model,x, \"peia_new.onnx\")"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPAj/aQBwL2lhdlIS8pnKF4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.8.16"}},"nbformat":4,"nbformat_minor":0}
